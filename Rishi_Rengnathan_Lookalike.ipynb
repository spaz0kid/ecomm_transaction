{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmCmEibasb3e",
        "outputId": "56ef4768-ef9c-4f9b-d52e-8d35f3324193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the file paths (update paths to match your folder structure in Drive)\n",
        "customers_path = '/content/drive/MyDrive/Customers.csv'\n",
        "products_path = '/content/drive/MyDrive/Products.csv'\n",
        "transactions_path = '/content/drive/MyDrive/Transactions.csv'\n",
        "\n",
        "# Load the datasets\n",
        "import pandas as pd\n",
        "customers = pd.read_csv(customers_path)\n",
        "products = pd.read_csv(products_path)\n",
        "transactions = pd.read_csv(transactions_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge transactions with products to include product details\n",
        "transactions = transactions.merge(products, on='ProductID')\n",
        "\n",
        "# Merge the above with customers to have a complete dataset\n",
        "full_data = transactions.merge(customers, on='CustomerID')"
      ],
      "metadata": {
        "id": "m8uoGqEmtDbL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating aggregated features by customer\n",
        "features = full_data.groupby('CustomerID').agg({\n",
        "    'TotalValue': ['sum', 'mean'],  # Total and average transaction value\n",
        "    'ProductID': pd.Series.nunique,  # Number of unique products bought\n",
        "    'Category': lambda x: x.mode()[0]  # Most frequently purchased category\n",
        "}).reset_index()\n",
        "\n",
        "# Flatten the multi-level columns created by aggregation\n",
        "features.columns = ['CustomerID', 'TotalSpent', 'AverageSpent', 'UniqueProducts', 'FrequentCategory']\n",
        "\n",
        "# Encode the 'FrequentCategory' column as it's categorical\n",
        "features = pd.get_dummies(features, columns=['FrequentCategory'])"
      ],
      "metadata": {
        "id": "yS-rjhQXtHbg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scaling the numeric features\n",
        "scaler = StandardScaler()\n",
        "features[['TotalSpent', 'AverageSpent', 'UniqueProducts']] = scaler.fit_transform(features[['TotalSpent', 'AverageSpent', 'UniqueProducts']])"
      ],
      "metadata": {
        "id": "EKYv789htL4N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Prepare the feature matrix for similarity calculation\n",
        "feature_matrix = features.drop('CustomerID', axis=1).values\n",
        "\n",
        "# Compute the cosine similarity matrix\n",
        "similarity_matrix = cosine_similarity(feature_matrix)\n",
        "\n",
        "# Convert to DataFrame for easier handling\n",
        "similarity_df = pd.DataFrame(similarity_matrix, index=features['CustomerID'], columns=features['CustomerID'])"
      ],
      "metadata": {
        "id": "6MAOX5-NtRq3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_lookalikes(customer_id, num_lookalikes=3):\n",
        "    # Get all similarities for a given customer and remove self-similarity\n",
        "    all_scores = similarity_df.loc[customer_id].drop(customer_id)\n",
        "\n",
        "    # Get top scores\n",
        "    top_scores = all_scores.nlargest(num_lookalikes)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'CustomerID': top_scores.index,\n",
        "        'SimilarityScore': top_scores.values\n",
        "    })\n",
        "\n",
        "# Example usage: Get top 3 lookalikes for customer 'C0001'\n",
        "top_lookalikes_c0001 = get_top_lookalikes('C0001')\n",
        "print(top_lookalikes_c0001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC6-Gc3UtVjF",
        "outputId": "bf308205-d070-404b-f81b-7aa6667b9f9a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  CustomerID  SimilarityScore\n",
            "0      C0072         0.946213\n",
            "1      C0190         0.941674\n",
            "2      C0069         0.910715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_lookalikes(customer_id, num_lookalikes=3):\n",
        "    # Fetch scores for the given customer and drop self-comparison\n",
        "    all_scores = similarity_df.loc[customer_id].drop(customer_id)\n",
        "    # Get top scores\n",
        "    top_scores = all_scores.nlargest(num_lookalikes)\n",
        "    # Return list of tuples (each tuple: BaseCustomerID, LookalikeCustomerID, SimilarityScore)\n",
        "    return [(customer_id, idx, score) for idx, score in top_scores.items()]\n",
        "\n",
        "# List to collect all lookalike data\n",
        "lookalike_data = []\n",
        "\n",
        "# Get top lookalikes for selected customers and extend the list with new tuples\n",
        "for customer in selected_customers:\n",
        "    lookalike_data.extend(get_top_lookalikes(customer))\n",
        "\n",
        "# Create DataFrame from the list of tuples\n",
        "lookalike_df = pd.DataFrame(lookalike_data, columns=['BaseCustomerID', 'LookalikeCustomerID', 'SimilarityScore'])\n",
        "\n",
        "# Save to CSV\n",
        "lookalike_df.to_csv('Lookalike.csv', index=False)"
      ],
      "metadata": {
        "id": "Bn7660_wn7Lb"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}